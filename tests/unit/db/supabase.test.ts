/**
 * Comprehensive unit tests for src/db/supabase.ts
 * Covers all exported functions, internal handlers, helpers, and error branches.
 */

import { describe, it, expect, vi, beforeEach, afterEach } from "vitest";
import { PublicKey } from "@solana/web3.js";

// ─── Test fixtures ───────────────────────────────────────────────────────────

const TEST_ASSET = new PublicKey(new Uint8Array(32).fill(1));
const TEST_OWNER = new PublicKey(new Uint8Array(32).fill(2));
const TEST_NEW_OWNER = new PublicKey(new Uint8Array(32).fill(3));
const TEST_COLLECTION = new PublicKey(new Uint8Array(32).fill(4));
const TEST_CLIENT = new PublicKey(new Uint8Array(32).fill(6));
const TEST_VALIDATOR = new PublicKey(new Uint8Array(32).fill(7));
const TEST_WALLET = new PublicKey(new Uint8Array(32).fill(8));
const TEST_RESPONDER = new PublicKey(new Uint8Array(32).fill(9));
const DEFAULT_PUBKEY_KEY = new PublicKey("11111111111111111111111111111111");
const TEST_HASH = new Uint8Array(32).fill(0xab);
const TEST_SIGNATURE = "5wHu1qwD7q2ggbJqCPtxnHZ2TrLQfEV9B7NqcBYBqzXh9J6vQQYc4Kdb8ZnZJwZqNjKt1QZcJZGJ";
const TEST_SLOT = 12345678n;
const TEST_BLOCK_TIME = new Date("2024-01-15T10:00:00Z");

// ─── Mock pg Pool + PoolClient ───────────────────────────────────────────────

const { mockPoolInstance, mockClientInstance } = vi.hoisted(() => {
  const mockClientInstance = {
    query: vi.fn().mockResolvedValue({ rows: [], rowCount: 0 }),
    release: vi.fn(),
  };
  const mockPoolInstance = {
    query: vi.fn().mockResolvedValue({ rows: [], rowCount: 0 }),
    on: vi.fn(),
    connect: vi.fn().mockResolvedValue(mockClientInstance),
    end: vi.fn(),
  };
  return { mockPoolInstance, mockClientInstance };
});

vi.mock("pg", () => {
  class MockPool {
    constructor() {
      return mockPoolInstance as any;
    }
  }
  return { Pool: MockPool };
});

// ─── Mock config ─────────────────────────────────────────────────────────────

vi.mock("../../../src/config.js", async (importOriginal) => {
  const original = (await importOriginal()) as any;
  return {
    ...original,
    config: {
      ...original.config,
      dbMode: "supabase",
      supabaseDsn: "POSTGRES_DSN_REDACTED",
      supabaseSslVerify: false,
      metadataIndexMode: "off",
      metadataMaxValueBytes: 10000,
      metadataTimeoutMs: 5000,
      metadataMaxBytes: 100000,
    },
  };
});

// ─── Mock logger (noop) ──────────────────────────────────────────────────────

vi.mock("../../../src/logger.js", () => ({
  createChildLogger: () => ({
    info: vi.fn(),
    warn: vi.fn(),
    error: vi.fn(),
    debug: vi.fn(),
  }),
  logger: {
    info: vi.fn(),
    warn: vi.fn(),
    error: vi.fn(),
    debug: vi.fn(),
    child: () => ({
      info: vi.fn(),
      warn: vi.fn(),
      error: vi.fn(),
      debug: vi.fn(),
    }),
  },
}));

// ─── Mock metadata-queue ─────────────────────────────────────────────────────

const mockMetadataQueue = {
  setPool: vi.fn(),
  add: vi.fn(),
  addBatch: vi.fn(),
};

vi.mock("../../../src/indexer/metadata-queue.js", () => ({
  metadataQueue: mockMetadataQueue,
}));

// ─── Mock uriDigest ──────────────────────────────────────────────────────────

const mockDigestUri = vi.fn().mockResolvedValue({
  status: "ok",
  fields: { "_uri:name": "TestAgent", "_uri:description": "A test agent" },
  bytes: 512,
  hash: "abc123",
});
const mockSerializeValue = vi.fn().mockReturnValue({ value: "test", oversize: false, bytes: 4 });

vi.mock("../../../src/indexer/uriDigest.js", () => ({
  digestUri: mockDigestUri,
  serializeValue: mockSerializeValue,
}));

// ─── Mock compression ────────────────────────────────────────────────────────

const mockCompressForStorage = vi.fn().mockResolvedValue(
  Buffer.concat([Buffer.from([0x00]), Buffer.from("test")])
);

vi.mock("../../../src/utils/compression.js", () => ({
  compressForStorage: mockCompressForStorage,
}));

// ─── Mock sanitize ───────────────────────────────────────────────────────────

vi.mock("../../../src/utils/sanitize.js", () => ({
  stripNullBytes: vi.fn().mockImplementation((data: Uint8Array) => Buffer.from(data)),
}));

// ─── Import module under test AFTER all vi.mock() calls ──────────────────────

const {
  getPool,
  handleEvent,
  handleEventAtomic,
  loadIndexerState,
  saveIndexerState,
} = await import("../../../src/db/supabase.js");

// Access config for runtime manipulation
const { config } = await import("../../../src/config.js");

// Capture the initial pool.on handlers that were registered at import time
// (getPool() is called lazily on first handleEvent, but we force it here)
getPool();
const initialOnCalls = [...mockPoolInstance.on.mock.calls];
const poolErrorHandler = initialOnCalls.find((c: any[]) => c[0] === "error")?.[1];
const poolConnectHandler = initialOnCalls.find((c: any[]) => c[0] === "connect")?.[1];

// ─── Helpers ─────────────────────────────────────────────────────────────────

function defaultCtx() {
  return {
    signature: TEST_SIGNATURE,
    slot: TEST_SLOT,
    blockTime: TEST_BLOCK_TIME,
    txIndex: 0,
  };
}

function resetPoolMocks() {
  mockPoolInstance.query.mockReset();
  mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 0 });
  mockPoolInstance.on.mockClear();
  mockPoolInstance.connect.mockClear();
  mockPoolInstance.connect.mockResolvedValue(mockClientInstance);

  mockClientInstance.query.mockReset();
  mockClientInstance.query.mockResolvedValue({ rows: [], rowCount: 0 });
  mockClientInstance.release.mockClear();
}

// ─── Tests ───────────────────────────────────────────────────────────────────

describe("supabase.ts", () => {
  let ctx: ReturnType<typeof defaultCtx>;

  beforeEach(() => {
    ctx = defaultCtx();
    resetPoolMocks();
    mockMetadataQueue.setPool.mockClear();
    mockMetadataQueue.add.mockClear();
    mockDigestUri.mockClear();
    mockSerializeValue.mockClear();
    mockCompressForStorage.mockClear();
    mockCompressForStorage.mockResolvedValue(
      Buffer.concat([Buffer.from([0x00]), Buffer.from("test")])
    );
  });

  // =========================================================================
  // getPool()
  // =========================================================================

  describe("getPool()", () => {
    it("should return a Pool instance", () => {
      const pool = getPool();
      expect(pool).toBe(mockPoolInstance);
    });

    it("should return the same pool on subsequent calls (singleton)", () => {
      const pool1 = getPool();
      const pool2 = getPool();
      expect(pool1).toBe(pool2);
    });

    it("should have registered error and connect handlers at init time", () => {
      const eventNames = initialOnCalls.map((c: any[]) => c[0]);
      expect(eventNames).toContain("error");
      expect(eventNames).toContain("connect");
    });

    it("should have initialized metadata queue with pool at init time", () => {
      // setPool was called during the first getPool() invocation (at import time)
      // We verify by checking the handler was registered (captured before beforeEach clears)
      // Since setPool was called at module load, the initial call count > 0
      // Re-verify by checking the pool instance is the mock
      expect(getPool()).toBe(mockPoolInstance);
    });

    it("pool error handler should log and increment error stats", () => {
      expect(poolErrorHandler).toBeDefined();
      poolErrorHandler(new Error("pool error"));
      // No throw expected, just logged
    });

    it("pool connect handler should not throw", () => {
      expect(poolConnectHandler).toBeDefined();
      poolConnectHandler();
    });
  });

  // =========================================================================
  // handleEvent() - deprecated non-atomic handler
  // =========================================================================

  describe("handleEvent()", () => {
    describe("AgentRegistered", () => {
      it("should insert agent with URI", async () => {
        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: TEST_COLLECTION,
            owner: TEST_OWNER,
            atomEnabled: true,
            agentUri: "ipfs://QmTest",
          },
        };
        await handleEvent(event, ctx);
        // ensureCollection + agent insert
        expect(mockPoolInstance.query).toHaveBeenCalled();
        const calls = mockPoolInstance.query.mock.calls;
        const insertCall = calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO agents")
        );
        expect(insertCall).toBeDefined();
        expect(insertCall![1]).toContain(TEST_ASSET.toBase58());
        expect(insertCall![1]).toContain("ipfs://QmTest");
      });

      it("should insert agent without URI (null)", async () => {
        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: TEST_COLLECTION,
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "",
          },
        };
        await handleEvent(event, ctx);
        const calls = mockPoolInstance.query.mock.calls;
        const insertCall = calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO agents")
        );
        expect(insertCall).toBeDefined();
        expect(insertCall![1]).toContain(null); // agentUri is null
      });

      it("should catch and log error on query failure", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("collection fail"));
        mockPoolInstance.query.mockRejectedValueOnce(new Error("insert fail"));
        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: TEST_COLLECTION,
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "",
          },
        };
        // handleAgentRegistered has try/catch so should not throw
        await handleEvent(event, ctx);
      });

      it("should catch digestAndStoreUriMetadata rejection in .catch() handler", async () => {
        (config as any).metadataIndexMode = "normal";
        try {
          mockPoolInstance.query.mockImplementation((text: string) => {
            if (typeof text === "string" && text.includes("SELECT agent_uri")) {
              return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmDigestFail" }], rowCount: 1 });
            }
            return Promise.resolve({ rows: [], rowCount: 1 });
          });
          mockDigestUri.mockRejectedValue(new Error("digestUri crashed"));

          const event = {
            type: "AgentRegistered" as const,
            data: {
              asset: TEST_ASSET,
              collection: new PublicKey(new Uint8Array(32).fill(92)),
              owner: TEST_OWNER,
              atomEnabled: false,
              agentUri: "ipfs://QmDigestFail",
            },
          };
          await handleEvent(event, ctx);
          await new Promise((r) => setTimeout(r, 100));
          // The .catch() in handleAgentRegistered catches the rejection
        } finally {
          mockDigestUri.mockResolvedValue({
            status: "ok",
            fields: {},
            bytes: 0,
            hash: "abc",
          });
          (config as any).metadataIndexMode = "off";
        }
      });
    });

    describe("AgentOwnerSynced", () => {
      it("should update agent owner", async () => {
        const event = {
          type: "AgentOwnerSynced" as const,
          data: {
            asset: TEST_ASSET,
            oldOwner: TEST_OWNER,
            newOwner: TEST_NEW_OWNER,
          },
        };
        await handleEvent(event, ctx);
        const calls = mockPoolInstance.query.mock.calls;
        const updateCall = calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("UPDATE agents SET owner")
        );
        expect(updateCall).toBeDefined();
        expect(updateCall![1]).toContain(TEST_NEW_OWNER.toBase58());
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("update fail"));
        const event = {
          type: "AgentOwnerSynced" as const,
          data: {
            asset: TEST_ASSET,
            oldOwner: TEST_OWNER,
            newOwner: TEST_NEW_OWNER,
          },
        };
        await handleEvent(event, ctx);
        // No throw
      });
    });

    describe("AtomEnabled", () => {
      it("should update atom_enabled on agent", async () => {
        const event = {
          type: "AtomEnabled" as const,
          data: {
            asset: TEST_ASSET,
            enabledBy: TEST_OWNER,
          },
        };
        await handleEvent(event, ctx);
        const calls = mockPoolInstance.query.mock.calls;
        const updateCall = calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("atom_enabled = true")
        );
        expect(updateCall).toBeDefined();
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "AtomEnabled" as const,
          data: { asset: TEST_ASSET, enabledBy: TEST_OWNER },
        };
        await handleEvent(event, ctx);
      });
    });

    describe("UriUpdated", () => {
      it("should update agent_uri", async () => {
        const event = {
          type: "UriUpdated" as const,
          data: {
            asset: TEST_ASSET,
            newUri: "ipfs://QmNewUri",
            updatedBy: TEST_OWNER,
          },
        };
        await handleEvent(event, ctx);
        const updateCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("UPDATE agents SET agent_uri")
        );
        expect(updateCall).toBeDefined();
        expect(updateCall![1][0]).toBe("ipfs://QmNewUri");
      });

      it("should set agent_uri to null when empty", async () => {
        const event = {
          type: "UriUpdated" as const,
          data: {
            asset: TEST_ASSET,
            newUri: "",
            updatedBy: TEST_OWNER,
          },
        };
        await handleEvent(event, ctx);
        const updateCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("UPDATE agents SET agent_uri")
        );
        expect(updateCall![1][0]).toBeNull();
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "UriUpdated" as const,
          data: { asset: TEST_ASSET, newUri: "x", updatedBy: TEST_OWNER },
        };
        await handleEvent(event, ctx);
      });
    });

    describe("WalletUpdated", () => {
      it("should update agent_wallet with normal wallet", async () => {
        const event = {
          type: "WalletUpdated" as const,
          data: {
            asset: TEST_ASSET,
            oldWallet: null,
            newWallet: TEST_WALLET,
            updatedBy: TEST_OWNER,
          },
        };
        await handleEvent(event, ctx);
        const updateCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("agent_wallet")
        );
        expect(updateCall).toBeDefined();
        expect(updateCall![1][0]).toBe(TEST_WALLET.toBase58());
      });

      it("should set wallet to null when DEFAULT_PUBKEY (wallet reset)", async () => {
        const event = {
          type: "WalletUpdated" as const,
          data: {
            asset: TEST_ASSET,
            oldWallet: TEST_WALLET,
            newWallet: DEFAULT_PUBKEY_KEY,
            updatedBy: TEST_OWNER,
          },
        };
        await handleEvent(event, ctx);
        const updateCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("agent_wallet")
        );
        expect(updateCall![1][0]).toBeNull();
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "WalletUpdated" as const,
          data: { asset: TEST_ASSET, oldWallet: null, newWallet: TEST_WALLET, updatedBy: TEST_OWNER },
        };
        await handleEvent(event, ctx);
      });
    });

    describe("MetadataSet", () => {
      it("should insert metadata with compressed value", async () => {
        const event = {
          type: "MetadataSet" as const,
          data: {
            asset: TEST_ASSET,
            key: "website",
            value: new Uint8Array([104, 116, 116, 112]),
            immutable: false,
          },
        };
        await handleEvent(event, ctx);
        const insertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO metadata")
        );
        expect(insertCall).toBeDefined();
        expect(mockCompressForStorage).toHaveBeenCalled();
      });

      it("should skip _uri: prefixed keys", async () => {
        const event = {
          type: "MetadataSet" as const,
          data: {
            asset: TEST_ASSET,
            key: "_uri:name",
            value: new Uint8Array([1, 2, 3]),
            immutable: false,
          },
        };
        await handleEvent(event, ctx);
        const insertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO metadata")
        );
        expect(insertCall).toBeUndefined();
      });

      it("should handle immutable metadata", async () => {
        const event = {
          type: "MetadataSet" as const,
          data: {
            asset: TEST_ASSET,
            key: "frozen_key",
            value: new Uint8Array([10, 20]),
            immutable: true,
          },
        };
        await handleEvent(event, ctx);
        const insertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO metadata")
        );
        expect(insertCall).toBeDefined();
        // immutable param
        expect(insertCall![1][5]).toBe(true);
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "MetadataSet" as const,
          data: { asset: TEST_ASSET, key: "k", value: new Uint8Array([1]), immutable: false },
        };
        await handleEvent(event, ctx);
      });
    });

    describe("MetadataDeleted", () => {
      it("should delete metadata by asset and key", async () => {
        const event = {
          type: "MetadataDeleted" as const,
          data: { asset: TEST_ASSET, key: "website" },
        };
        await handleEvent(event, ctx);
        const deleteCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("DELETE FROM metadata")
        );
        expect(deleteCall).toBeDefined();
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "MetadataDeleted" as const,
          data: { asset: TEST_ASSET, key: "k" },
        };
        await handleEvent(event, ctx);
      });
    });

    describe("RegistryInitialized", () => {
      it("should upsert collection with authority", async () => {
        const event = {
          type: "RegistryInitialized" as const,
          data: {
            collection: TEST_COLLECTION,
            authority: TEST_OWNER,
          },
        };
        await handleEvent(event, ctx);
        const insertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO collections") && c[0].includes("authority")
        );
        expect(insertCall).toBeDefined();
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "RegistryInitialized" as const,
          data: { collection: TEST_COLLECTION, authority: TEST_OWNER },
        };
        await handleEvent(event, ctx);
      });
    });

    describe("NewFeedback", () => {
      function makeFeedbackData(overrides: Record<string, any> = {}) {
        return {
          asset: TEST_ASSET,
          clientAddress: TEST_CLIENT,
          feedbackIndex: 0n,
          slot: 123456n,
          value: 9500n,
          valueDecimals: 2,
          score: 85,
          feedbackFileHash: null,
          sealHash: TEST_HASH,
          atomEnabled: true,
          newTrustTier: 1,
          newQualityScore: 8500,
          newConfidence: 100,
          newRiskScore: 0,
          newDiversityRatio: 10000,
          isUniqueClient: true,
          newFeedbackDigest: TEST_HASH,
          newFeedbackCount: 1n,
          tag1: "quality",
          tag2: "speed",
          endpoint: "/api/chat",
          feedbackUri: "ipfs://QmXXX",
          ...overrides,
        };
      }

      it("should insert feedback with atomEnabled=true and update agent ATOM stats", async () => {
        mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 1 });
        const event = {
          type: "NewFeedback" as const,
          data: makeFeedbackData({ atomEnabled: true }),
        };
        await handleEvent(event, ctx);
        const calls = mockPoolInstance.query.mock.calls;
        const insertCall = calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO feedbacks")
        );
        expect(insertCall).toBeDefined();
        const atomUpdateCall = calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("trust_tier")
        );
        expect(atomUpdateCall).toBeDefined();
      });

      it("should insert feedback with atomEnabled=false (no ATOM update)", async () => {
        mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 1 });
        const event = {
          type: "NewFeedback" as const,
          data: makeFeedbackData({ atomEnabled: false }),
        };
        await handleEvent(event, ctx);
        const calls = mockPoolInstance.query.mock.calls;
        const updateCall = calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("UPDATE agents SET") && !c[0].includes("trust_tier")
        );
        expect(updateCall).toBeDefined();
      });

      it("should handle duplicate feedback (rowCount=0)", async () => {
        mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 0 });
        const event = {
          type: "NewFeedback" as const,
          data: makeFeedbackData(),
        };
        await handleEvent(event, ctx);
        // Only the insert query should be called, not the UPDATE agents
        const calls = mockPoolInstance.query.mock.calls;
        // First calls: ensureCollection insert + feedback insert (which returns rowCount=0)
        // No UPDATE agents calls after
        const updateCalls = calls.filter((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("UPDATE agents SET")
        );
        expect(updateCalls.length).toBe(0);
      });

      it("should include sealHash as feedback_hash", async () => {
        mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 1 });
        const event = {
          type: "NewFeedback" as const,
          data: makeFeedbackData(),
        };
        await handleEvent(event, ctx);
        const insertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO feedbacks")
        );
        const expectedHash = Buffer.from(TEST_HASH).toString("hex");
        expect(insertCall![1]).toContain(expectedHash);
      });

      it("should handle null sealHash", async () => {
        mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 1 });
        const data = makeFeedbackData();
        (data as any).sealHash = null;
        const event = { type: "NewFeedback" as const, data };
        await handleEvent(event, ctx);
        // Should not throw
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "NewFeedback" as const,
          data: makeFeedbackData(),
        };
        await handleEvent(event, ctx);
      });
    });

    describe("FeedbackRevoked", () => {
      function makeRevokeData(overrides: Record<string, any> = {}) {
        return {
          asset: TEST_ASSET,
          clientAddress: TEST_CLIENT,
          feedbackIndex: 0n,
          sealHash: TEST_HASH,
          slot: 123456n,
          originalScore: 85,
          atomEnabled: true,
          hadImpact: true,
          newTrustTier: 0,
          newQualityScore: 7000,
          newConfidence: 90,
          newRevokeDigest: TEST_HASH,
          newRevokeCount: 1n,
          ...overrides,
        };
      }

      it("should revoke feedback when feedback exists with matching hash", async () => {
        const storedHash = Buffer.from(TEST_HASH).toString("hex");
        mockPoolInstance.query
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: storedHash }], rowCount: 1 }) // SELECT feedback
          .mockResolvedValue({ rows: [], rowCount: 1 }); // subsequent updates

        const event = {
          type: "FeedbackRevoked" as const,
          data: makeRevokeData(),
        };
        await handleEvent(event, ctx);

        const updateCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("is_revoked = true")
        );
        expect(updateCall).toBeDefined();
      });

      it("should handle orphan revoke (feedback not found)", async () => {
        mockPoolInstance.query
          .mockResolvedValueOnce({ rows: [], rowCount: 0 }) // SELECT feedback not found
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "FeedbackRevoked" as const,
          data: makeRevokeData(),
        };
        await handleEvent(event, ctx);
        const revokeInsert = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO revocations")
        );
        expect(revokeInsert).toBeDefined();
        expect(revokeInsert![1]).toContain("ORPHANED");
      });

      it("should keep revocation insert idempotent for parallel duplicate events", async () => {
        mockPoolInstance.query.mockImplementation((queryText: any) => {
          if (typeof queryText === "string" && queryText.includes("SELECT id, feedback_hash FROM feedbacks")) {
            return Promise.resolve({ rows: [], rowCount: 0 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });

        const event = {
          type: "FeedbackRevoked" as const,
          data: makeRevokeData(),
        };

        await Promise.all([
          handleEvent(event, ctx),
          handleEvent(event, ctx),
        ]);

        const revokeInsertCalls = mockPoolInstance.query.mock.calls.filter((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO revocations")
        );

        expect(revokeInsertCalls).toHaveLength(2);
        for (const call of revokeInsertCalls) {
          expect(call[0]).toContain("ON CONFLICT (asset, client_address, feedback_index)");
          expect(call[0]).toMatch(/DO (NOTHING|UPDATE SET)/);
        }
      });

      it("should warn on seal_hash mismatch", async () => {
        mockPoolInstance.query
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: "ff".repeat(32) }], rowCount: 1 }) // mismatched hash
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "FeedbackRevoked" as const,
          data: makeRevokeData(),
        };
        await handleEvent(event, ctx);
        // Should not throw, just warns
      });

      it("should update ATOM stats when atomEnabled + hadImpact", async () => {
        const storedHash = Buffer.from(TEST_HASH).toString("hex");
        mockPoolInstance.query
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: storedHash }], rowCount: 1 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "FeedbackRevoked" as const,
          data: makeRevokeData({ atomEnabled: true, hadImpact: true }),
        };
        await handleEvent(event, ctx);
        const atomUpdate = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("trust_tier") && c[0].includes("quality_score") && c[0].includes("confidence")
        );
        expect(atomUpdate).toBeDefined();
      });

      it("should skip ATOM update when hadImpact=false", async () => {
        const storedHash = Buffer.from(TEST_HASH).toString("hex");
        mockPoolInstance.query
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: storedHash }], rowCount: 1 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "FeedbackRevoked" as const,
          data: makeRevokeData({ atomEnabled: true, hadImpact: false }),
        };
        await handleEvent(event, ctx);
        const atomUpdate = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("trust_tier") && c[0].includes("quality_score") && c[0].includes("confidence")
        );
        expect(atomUpdate).toBeUndefined();
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "FeedbackRevoked" as const,
          data: makeRevokeData(),
        };
        await handleEvent(event, ctx);
      });
    });

    describe("ResponseAppended", () => {
      function makeResponseData(overrides: Record<string, any> = {}) {
        return {
          asset: TEST_ASSET,
          client: TEST_CLIENT,
          feedbackIndex: 0n,
          slot: 123456n,
          responder: TEST_RESPONDER,
          responseUri: "ipfs://QmResp",
          responseHash: TEST_HASH,
          sealHash: TEST_HASH,
          newResponseDigest: TEST_HASH,
          newResponseCount: 1n,
          ...overrides,
        };
      }

      it("should store response when feedback exists with matching hash", async () => {
        const storedHash = Buffer.from(TEST_HASH).toString("hex");
        mockPoolInstance.query
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: storedHash }], rowCount: 1 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "ResponseAppended" as const,
          data: makeResponseData(),
        };
        await handleEvent(event, ctx);
        const insertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO feedback_responses")
        );
        expect(insertCall).toBeDefined();
        expect(insertCall![1]).toContain("PENDING");
      });

      it("should store as orphan when feedback not found", async () => {
        mockPoolInstance.query
          .mockResolvedValueOnce({ rows: [], rowCount: 0 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "ResponseAppended" as const,
          data: makeResponseData(),
        };
        await handleEvent(event, ctx);
        const insertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO feedback_responses")
        );
        expect(insertCall).toBeDefined();
        expect(insertCall![1]).toContain("ORPHANED");
      });

      it("should warn on seal_hash mismatch", async () => {
        mockPoolInstance.query
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: "ff".repeat(32) }], rowCount: 1 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "ResponseAppended" as const,
          data: makeResponseData(),
        };
        await handleEvent(event, ctx);
        // Should not throw
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "ResponseAppended" as const,
          data: makeResponseData(),
        };
        await handleEvent(event, ctx);
      });
    });

    describe("ValidationRequested", () => {
      it("should insert validation request", async () => {
        const event = {
          type: "ValidationRequested" as const,
          data: {
            asset: TEST_ASSET,
            validatorAddress: TEST_VALIDATOR,
            nonce: 1n,
            requestUri: "ipfs://QmReq",
            requestHash: TEST_HASH,
            requester: TEST_OWNER,
          },
        };
        await handleEvent(event, ctx);
        const insertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO validations")
        );
        expect(insertCall).toBeDefined();
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "ValidationRequested" as const,
          data: {
            asset: TEST_ASSET,
            validatorAddress: TEST_VALIDATOR,
            nonce: 1n,
            requestUri: "",
            requestHash: TEST_HASH,
            requester: TEST_OWNER,
          },
        };
        await handleEvent(event, ctx);
      });
    });

    describe("ValidationResponded", () => {
      it("should upsert validation response", async () => {
        const event = {
          type: "ValidationResponded" as const,
          data: {
            asset: TEST_ASSET,
            validatorAddress: TEST_VALIDATOR,
            nonce: 1n,
            response: 90,
            responseUri: "ipfs://QmResp",
            responseHash: TEST_HASH,
            tag: "verified",
          },
        };
        await handleEvent(event, ctx);
        const upsertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO validations") && c[0].includes("response")
        );
        expect(upsertCall).toBeDefined();
        // "RESPONDED" is a parameter value
        expect(upsertCall![1]).toContain("RESPONDED");
      });

      it("should handle null optional fields", async () => {
        const event = {
          type: "ValidationResponded" as const,
          data: {
            asset: TEST_ASSET,
            validatorAddress: TEST_VALIDATOR,
            nonce: 2n,
            response: 50,
            responseUri: "",
            responseHash: null as any,
            tag: "",
          },
        };
        await handleEvent(event, ctx);
        // Should not throw
      });

      it("should catch query error", async () => {
        mockPoolInstance.query.mockRejectedValueOnce(new Error("fail"));
        const event = {
          type: "ValidationResponded" as const,
          data: {
            asset: TEST_ASSET,
            validatorAddress: TEST_VALIDATOR,
            nonce: 1n,
            response: 90,
            responseUri: "",
            responseHash: TEST_HASH,
            tag: "",
          },
        };
        await handleEvent(event, ctx);
      });
    });

    describe("Unknown event type", () => {
      it("should log warning for unknown event type", async () => {
        const event = { type: "SomethingNew", data: {} } as any;
        await handleEvent(event, ctx);
        // No throw expected
      });
    });

    describe("Slow event warning", () => {
      it("should warn when event processing exceeds 1000ms", async () => {
        const originalDateNow = Date.now;
        let callCount = 0;
        vi.spyOn(Date, "now").mockImplementation(() => {
          callCount++;
          // First call is startTime, subsequent calls add 1500ms
          if (callCount <= 1) return 1000;
          return 2500;
        });

        const event = {
          type: "AgentOwnerSynced" as const,
          data: { asset: TEST_ASSET, oldOwner: TEST_OWNER, newOwner: TEST_NEW_OWNER },
        };
        await handleEvent(event, ctx);

        vi.spyOn(Date, "now").mockRestore();
      });
    });

    describe("Error handling re-throw", () => {
      it("should re-throw errors from the switch block", async () => {
        // Force an error that escapes the inner try/catch of individual handlers.
        // For handleEvent, each handler has its own try/catch that swallows errors,
        // but the outer try/catch in handleEvent also catches and re-throws.
        // We need to make the switch code itself throw (e.g., before handler try/catch).
        // The easiest way is to have data.asset.toBase58() throw.
        const event = {
          type: "AtomEnabled" as const,
          data: {
            asset: { toBase58: () => { throw new Error("toBase58 exploded"); } },
            enabledBy: TEST_OWNER,
          },
        };
        // handleAtomEnabled has try/catch, but getPool is called first which won't fail.
        // Actually the toBase58 is inside try/catch in the handler. Let's verify error pathway.
        // The getPool() call succeeds, then db.query fails, which is caught.
        // For the outer catch to fire, we'd need something before the inner try.
        // Let's test handleEvent re-throw by having a handler that does throw through
        // its catch. Actually the non-tx handlers catch internally and don't rethrow.
        // The outer catch in handleEvent only fires if the switch statement itself fails.
        // Test by making event.type accessor throw:
        const badEvent = Object.create(null);
        Object.defineProperty(badEvent, "type", {
          get() { throw new Error("type accessor exploded"); }
        });
        await expect(handleEvent(badEvent, ctx)).rejects.toThrow("type accessor exploded");
      });
    });
  });

  // =========================================================================
  // handleEventAtomic() - transaction-based handler
  // =========================================================================

  describe("handleEventAtomic()", () => {
    it("should wrap event in BEGIN/COMMIT transaction", async () => {
      const event = {
        type: "AgentOwnerSynced" as const,
        data: { asset: TEST_ASSET, oldOwner: TEST_OWNER, newOwner: TEST_NEW_OWNER },
      };
      await handleEventAtomic(event, { ...ctx, source: "poller" as const });

      const queries = mockClientInstance.query.mock.calls.map((c: any[]) => c[0]);
      expect(queries[0]).toBe("BEGIN");
      expect(queries[queries.length - 1]).toBe("COMMIT");
    });

    it("should call client.release() in finally block", async () => {
      const event = {
        type: "AtomEnabled" as const,
        data: { asset: TEST_ASSET, enabledBy: TEST_OWNER },
      };
      await handleEventAtomic(event, { ...ctx, source: "websocket" as const });
      expect(mockClientInstance.release).toHaveBeenCalled();
    });

    it("should ROLLBACK on error and re-throw", async () => {
      mockClientInstance.query
        .mockResolvedValueOnce(undefined) // BEGIN
        .mockRejectedValueOnce(new Error("tx fail")); // handler query

      const event = {
        type: "AtomEnabled" as const,
        data: { asset: TEST_ASSET, enabledBy: TEST_OWNER },
      };
      await expect(handleEventAtomic(event, ctx)).rejects.toThrow("tx fail");
      const queries = mockClientInstance.query.mock.calls.map((c: any[]) => c[0]);
      expect(queries).toContain("ROLLBACK");
      expect(mockClientInstance.release).toHaveBeenCalled();
    });

    it("should use default source 'poller' in cursor update", async () => {
      const event = {
        type: "RegistryInitialized" as const,
        data: { collection: TEST_COLLECTION, authority: TEST_OWNER },
      };
      // ctx has no source
      await handleEventAtomic(event, { ...ctx });
      const cursorCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
        typeof c[0] === "string" && c[0].includes("indexer_state")
      );
      expect(cursorCall).toBeDefined();
      expect(cursorCall![1]).toContain("poller");
    });

    describe("All event types via atomic handler", () => {
      it("AgentRegistered", async () => {
        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: TEST_COLLECTION,
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "https://example.com/agent.json",
          },
        };
        await handleEventAtomic(event, ctx);
        const insertCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO agents")
        );
        expect(insertCall).toBeDefined();
      });

      it("AgentRegistered with metadataIndexMode on queues metadata", async () => {
        (config as any).metadataIndexMode = "normal";
        try {
          const event = {
            type: "AgentRegistered" as const,
            data: {
              asset: TEST_ASSET,
              collection: TEST_COLLECTION,
              owner: TEST_OWNER,
              atomEnabled: false,
              agentUri: "ipfs://QmTest",
            },
          };
          await handleEventAtomic(event, ctx);
          expect(mockMetadataQueue.add).toHaveBeenCalledWith(
            TEST_ASSET.toBase58(),
            "ipfs://QmTest"
          );
        } finally {
          (config as any).metadataIndexMode = "off";
        }
      });

      it("AgentRegistered without agentUri should not queue metadata", async () => {
        (config as any).metadataIndexMode = "normal";
        try {
          const event = {
            type: "AgentRegistered" as const,
            data: {
              asset: TEST_ASSET,
              collection: TEST_COLLECTION,
              owner: TEST_OWNER,
              atomEnabled: false,
              agentUri: "",
            },
          };
          await handleEventAtomic(event, ctx);
          expect(mockMetadataQueue.add).not.toHaveBeenCalled();
        } finally {
          (config as any).metadataIndexMode = "off";
        }
      });

      it("AgentOwnerSynced", async () => {
        const event = {
          type: "AgentOwnerSynced" as const,
          data: { asset: TEST_ASSET, oldOwner: TEST_OWNER, newOwner: TEST_NEW_OWNER },
        };
        await handleEventAtomic(event, ctx);
        const updateCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("UPDATE agents SET owner")
        );
        expect(updateCall).toBeDefined();
      });

      it("AtomEnabled", async () => {
        const event = {
          type: "AtomEnabled" as const,
          data: { asset: TEST_ASSET, enabledBy: TEST_OWNER },
        };
        await handleEventAtomic(event, ctx);
        const updateCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("atom_enabled = true")
        );
        expect(updateCall).toBeDefined();
      });

      it("UriUpdated with URI", async () => {
        const event = {
          type: "UriUpdated" as const,
          data: { asset: TEST_ASSET, newUri: "ipfs://new", updatedBy: TEST_OWNER },
        };
        await handleEventAtomic(event, ctx);
        const updateCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("UPDATE agents SET agent_uri")
        );
        expect(updateCall).toBeDefined();
        expect(updateCall![1][0]).toBe("ipfs://new");
      });

      it("UriUpdated with empty URI (null)", async () => {
        const event = {
          type: "UriUpdated" as const,
          data: { asset: TEST_ASSET, newUri: "", updatedBy: TEST_OWNER },
        };
        await handleEventAtomic(event, ctx);
        const updateCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("UPDATE agents SET agent_uri")
        );
        expect(updateCall![1][0]).toBeNull();
      });

      it("UriUpdated queues metadata when metadataIndexMode is on", async () => {
        (config as any).metadataIndexMode = "normal";
        try {
          const event = {
            type: "UriUpdated" as const,
            data: { asset: TEST_ASSET, newUri: "ipfs://updated", updatedBy: TEST_OWNER },
          };
          await handleEventAtomic(event, ctx);
          expect(mockMetadataQueue.add).toHaveBeenCalledWith(
            TEST_ASSET.toBase58(),
            "ipfs://updated"
          );
        } finally {
          (config as any).metadataIndexMode = "off";
        }
      });

      it("WalletUpdated normal wallet", async () => {
        const event = {
          type: "WalletUpdated" as const,
          data: { asset: TEST_ASSET, oldWallet: null, newWallet: TEST_WALLET, updatedBy: TEST_OWNER },
        };
        await handleEventAtomic(event, ctx);
        const updateCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("agent_wallet")
        );
        expect(updateCall![1][0]).toBe(TEST_WALLET.toBase58());
      });

      it("WalletUpdated DEFAULT_PUBKEY resets to null", async () => {
        const event = {
          type: "WalletUpdated" as const,
          data: { asset: TEST_ASSET, oldWallet: TEST_WALLET, newWallet: DEFAULT_PUBKEY_KEY, updatedBy: TEST_OWNER },
        };
        await handleEventAtomic(event, ctx);
        const updateCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("agent_wallet")
        );
        expect(updateCall![1][0]).toBeNull();
      });

      it("MetadataSet normal key", async () => {
        const event = {
          type: "MetadataSet" as const,
          data: { asset: TEST_ASSET, key: "website", value: new Uint8Array([1, 2, 3]), immutable: false },
        };
        await handleEventAtomic(event, ctx);
        const insertCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO metadata")
        );
        expect(insertCall).toBeDefined();
      });

      it("MetadataSet _uri: prefix key is skipped", async () => {
        const event = {
          type: "MetadataSet" as const,
          data: { asset: TEST_ASSET, key: "_uri:image", value: new Uint8Array([1]), immutable: false },
        };
        await handleEventAtomic(event, ctx);
        const insertCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO metadata")
        );
        expect(insertCall).toBeUndefined();
      });

      it("MetadataSet immutable flag", async () => {
        const event = {
          type: "MetadataSet" as const,
          data: { asset: TEST_ASSET, key: "frozen", value: new Uint8Array([9]), immutable: true },
        };
        await handleEventAtomic(event, ctx);
        const insertCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO metadata")
        );
        expect(insertCall).toBeDefined();
        expect(insertCall![1][5]).toBe(true); // immutable param
      });

      it("MetadataDeleted", async () => {
        const event = {
          type: "MetadataDeleted" as const,
          data: { asset: TEST_ASSET, key: "website" },
        };
        await handleEventAtomic(event, ctx);
        const deleteCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("DELETE FROM metadata")
        );
        expect(deleteCall).toBeDefined();
      });

      it("RegistryInitialized", async () => {
        const event = {
          type: "RegistryInitialized" as const,
          data: { collection: TEST_COLLECTION, authority: TEST_OWNER },
        };
        await handleEventAtomic(event, ctx);
        const insertCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO collections") && c[0].includes("authority")
        );
        expect(insertCall).toBeDefined();
      });

      it("NewFeedback with atomEnabled", async () => {
        mockClientInstance.query.mockResolvedValue({ rows: [], rowCount: 1 });
        const event = {
          type: "NewFeedback" as const,
          data: {
            asset: TEST_ASSET,
            clientAddress: TEST_CLIENT,
            feedbackIndex: 0n,
            slot: 123n,
            value: 9000n,
            valueDecimals: 2,
            score: 80,
            feedbackFileHash: null,
            sealHash: TEST_HASH,
            atomEnabled: true,
            newTrustTier: 2,
            newQualityScore: 8000,
            newConfidence: 500,
            newRiskScore: 5,
            newDiversityRatio: 200,
            isUniqueClient: true,
            newFeedbackDigest: TEST_HASH,
            newFeedbackCount: 1n,
            tag1: "uptime",
            tag2: "day",
            endpoint: "/chat",
            feedbackUri: "ipfs://Qm",
          },
        };
        await handleEventAtomic(event, ctx);
        const atomCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("trust_tier")
        );
        expect(atomCall).toBeDefined();
      });

      it("NewFeedback without atomEnabled", async () => {
        mockClientInstance.query.mockResolvedValue({ rows: [], rowCount: 1 });
        const event = {
          type: "NewFeedback" as const,
          data: {
            asset: TEST_ASSET,
            clientAddress: TEST_CLIENT,
            feedbackIndex: 0n,
            slot: 123n,
            value: 9000n,
            valueDecimals: 2,
            score: 80,
            feedbackFileHash: null,
            sealHash: TEST_HASH,
            atomEnabled: false,
            newTrustTier: 0,
            newQualityScore: 0,
            newConfidence: 0,
            newRiskScore: 0,
            newDiversityRatio: 0,
            isUniqueClient: false,
            newFeedbackDigest: TEST_HASH,
            newFeedbackCount: 1n,
            tag1: "",
            tag2: "",
            endpoint: "",
            feedbackUri: "",
          },
        };
        await handleEventAtomic(event, ctx);
        const updateCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("UPDATE agents SET") && !c[0].includes("trust_tier")
        );
        expect(updateCall).toBeDefined();
      });

      it("NewFeedback duplicate (rowCount=0)", async () => {
        mockClientInstance.query
          .mockResolvedValueOnce(undefined) // BEGIN
          .mockResolvedValueOnce({ rows: [], rowCount: 0 }); // INSERT returns 0 (dup)
        // after dup early-return, cursor update + COMMIT
        mockClientInstance.query.mockResolvedValue({ rows: [], rowCount: 0 });

        const event = {
          type: "NewFeedback" as const,
          data: {
            asset: TEST_ASSET,
            clientAddress: TEST_CLIENT,
            feedbackIndex: 0n,
            slot: 123n,
            value: 9000n,
            valueDecimals: 2,
            score: 80,
            feedbackFileHash: null,
            sealHash: TEST_HASH,
            atomEnabled: true,
            newTrustTier: 1,
            newQualityScore: 8000,
            newConfidence: 500,
            newRiskScore: 0,
            newDiversityRatio: 100,
            isUniqueClient: true,
            newFeedbackDigest: TEST_HASH,
            newFeedbackCount: 1n,
            tag1: "",
            tag2: "",
            endpoint: "",
            feedbackUri: "",
          },
        };
        await handleEventAtomic(event, ctx);
        // No UPDATE agents with trust_tier should happen after dup
      });

      it("FeedbackRevoked - feedback exists, matching hash, atomEnabled+hadImpact", async () => {
        const storedHash = Buffer.from(TEST_HASH).toString("hex");
        mockClientInstance.query
          .mockResolvedValueOnce(undefined) // BEGIN
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: storedHash }], rowCount: 1 }) // SELECT
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "FeedbackRevoked" as const,
          data: {
            asset: TEST_ASSET,
            clientAddress: TEST_CLIENT,
            feedbackIndex: 0n,
            sealHash: TEST_HASH,
            slot: 123n,
            originalScore: 80,
            atomEnabled: true,
            hadImpact: true,
            newTrustTier: 0,
            newQualityScore: 5000,
            newConfidence: 50,
            newRevokeDigest: TEST_HASH,
            newRevokeCount: 1n,
          },
        };
        await handleEventAtomic(event, ctx);
        const revokeCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("is_revoked = true")
        );
        expect(revokeCall).toBeDefined();
      });

      it("FeedbackRevoked - orphan (feedback not found)", async () => {
        mockClientInstance.query
          .mockResolvedValueOnce(undefined) // BEGIN
          .mockResolvedValueOnce({ rows: [], rowCount: 0 }) // SELECT not found
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "FeedbackRevoked" as const,
          data: {
            asset: TEST_ASSET,
            clientAddress: TEST_CLIENT,
            feedbackIndex: 0n,
            sealHash: TEST_HASH,
            slot: 123n,
            originalScore: 80,
            atomEnabled: false,
            hadImpact: false,
            newTrustTier: 0,
            newQualityScore: 0,
            newConfidence: 0,
            newRevokeDigest: TEST_HASH,
            newRevokeCount: 1n,
          },
        };
        await handleEventAtomic(event, ctx);
        const revokeInsert = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO revocations")
        );
        expect(revokeInsert).toBeDefined();
        expect(revokeInsert![1]).toContain("ORPHANED");
      });

      it("FeedbackRevoked - hash mismatch", async () => {
        mockClientInstance.query
          .mockResolvedValueOnce(undefined) // BEGIN
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: "cc".repeat(32) }], rowCount: 1 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "FeedbackRevoked" as const,
          data: {
            asset: TEST_ASSET,
            clientAddress: TEST_CLIENT,
            feedbackIndex: 0n,
            sealHash: TEST_HASH,
            slot: 123n,
            originalScore: 80,
            atomEnabled: false,
            hadImpact: false,
            newTrustTier: 0,
            newQualityScore: 0,
            newConfidence: 0,
            newRevokeDigest: TEST_HASH,
            newRevokeCount: 1n,
          },
        };
        await handleEventAtomic(event, ctx);
        // Warns but continues
      });

      it("ResponseAppended - feedback exists, matching hash", async () => {
        const storedHash = Buffer.from(TEST_HASH).toString("hex");
        mockClientInstance.query
          .mockResolvedValueOnce(undefined) // BEGIN
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: storedHash }], rowCount: 1 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "ResponseAppended" as const,
          data: {
            asset: TEST_ASSET,
            client: TEST_CLIENT,
            feedbackIndex: 0n,
            slot: 123n,
            responder: TEST_RESPONDER,
            responseUri: "ipfs://QmResp",
            responseHash: TEST_HASH,
            sealHash: TEST_HASH,
            newResponseDigest: TEST_HASH,
            newResponseCount: 1n,
          },
        };
        await handleEventAtomic(event, ctx);
        const insertCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO feedback_responses")
        );
        expect(insertCall).toBeDefined();
        expect(insertCall![1]).toContain("PENDING");
      });

      it("ResponseAppended - orphan", async () => {
        mockClientInstance.query
          .mockResolvedValueOnce(undefined) // BEGIN
          .mockResolvedValueOnce({ rows: [], rowCount: 0 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "ResponseAppended" as const,
          data: {
            asset: TEST_ASSET,
            client: TEST_CLIENT,
            feedbackIndex: 0n,
            slot: 123n,
            responder: TEST_RESPONDER,
            responseUri: "",
            responseHash: TEST_HASH,
            sealHash: TEST_HASH,
            newResponseDigest: TEST_HASH,
            newResponseCount: 1n,
          },
        };
        await handleEventAtomic(event, ctx);
        const insertCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO feedback_responses")
        );
        expect(insertCall).toBeDefined();
        expect(insertCall![1]).toContain("ORPHANED");
      });

      it("ResponseAppended - hash mismatch", async () => {
        mockClientInstance.query
          .mockResolvedValueOnce(undefined) // BEGIN
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: "dd".repeat(32) }], rowCount: 1 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "ResponseAppended" as const,
          data: {
            asset: TEST_ASSET,
            client: TEST_CLIENT,
            feedbackIndex: 0n,
            slot: 123n,
            responder: TEST_RESPONDER,
            responseUri: "ipfs://resp",
            responseHash: TEST_HASH,
            sealHash: TEST_HASH,
            newResponseDigest: TEST_HASH,
            newResponseCount: 1n,
          },
        };
        await handleEventAtomic(event, ctx);
      });

      it("NewFeedback with null sealHash and null newFeedbackDigest (Tx path)", async () => {
        mockClientInstance.query.mockResolvedValue({ rows: [], rowCount: 1 });
        const event = {
          type: "NewFeedback" as const,
          data: {
            asset: TEST_ASSET,
            clientAddress: TEST_CLIENT,
            feedbackIndex: 99n,
            slot: 123n,
            value: 100n,
            valueDecimals: 0,
            score: 50,
            feedbackFileHash: null,
            sealHash: null as any,
            atomEnabled: false,
            newTrustTier: 0,
            newQualityScore: 0,
            newConfidence: 0,
            newRiskScore: 0,
            newDiversityRatio: 0,
            isUniqueClient: false,
            newFeedbackDigest: null as any,
            newFeedbackCount: 1n,
            tag1: "",
            tag2: "",
            endpoint: "",
            feedbackUri: "",
          },
        };
        await handleEventAtomic(event, ctx);
        // Verifies the null branch of sealHash and newFeedbackDigest ternaries
      });

      it("FeedbackRevoked with null sealHash and null newRevokeDigest (Tx path)", async () => {
        mockClientInstance.query
          .mockResolvedValueOnce(undefined) // BEGIN
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: null }], rowCount: 1 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "FeedbackRevoked" as const,
          data: {
            asset: TEST_ASSET,
            clientAddress: TEST_CLIENT,
            feedbackIndex: 99n,
            sealHash: null as any,
            slot: 123n,
            originalScore: 50,
            atomEnabled: false,
            hadImpact: false,
            newTrustTier: 0,
            newQualityScore: 0,
            newConfidence: 0,
            newRevokeDigest: null as any,
            newRevokeCount: 0n,
          },
        };
        await handleEventAtomic(event, ctx);
        // Verifies the null branch of sealHash and newRevokeDigest ternaries
      });

      it("ResponseAppended with null responseHash, sealHash, newResponseDigest (Tx path)", async () => {
        mockClientInstance.query
          .mockResolvedValueOnce(undefined) // BEGIN
          .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: null }], rowCount: 1 })
          .mockResolvedValue({ rows: [], rowCount: 1 });

        const event = {
          type: "ResponseAppended" as const,
          data: {
            asset: TEST_ASSET,
            client: TEST_CLIENT,
            feedbackIndex: 99n,
            slot: 123n,
            responder: TEST_RESPONDER,
            responseUri: "",
            responseHash: null as any,
            sealHash: null as any,
            newResponseDigest: null as any,
            newResponseCount: 1n,
          },
        };
        await handleEventAtomic(event, ctx);
        // Verifies the null branch of responseHash, sealHash, and newResponseDigest ternaries
      });

      it("ValidationRequested with null requestHash and requestUri (Tx path)", async () => {
        const event = {
          type: "ValidationRequested" as const,
          data: {
            asset: TEST_ASSET,
            validatorAddress: TEST_VALIDATOR,
            nonce: 99n,
            requestUri: "",
            requestHash: null as any,
            requester: TEST_OWNER,
          },
        };
        await handleEventAtomic(event, ctx);
      });

      it("ValidationResponded with null responseHash and tag (Tx path)", async () => {
        const event = {
          type: "ValidationResponded" as const,
          data: {
            asset: TEST_ASSET,
            validatorAddress: TEST_VALIDATOR,
            nonce: 99n,
            response: 50,
            responseUri: "",
            responseHash: null as any,
            tag: "",
          },
        };
        await handleEventAtomic(event, ctx);
      });

      it("ValidationRequested", async () => {
        const event = {
          type: "ValidationRequested" as const,
          data: {
            asset: TEST_ASSET,
            validatorAddress: TEST_VALIDATOR,
            nonce: 5n,
            requestUri: "ipfs://QmReq",
            requestHash: TEST_HASH,
            requester: TEST_OWNER,
          },
        };
        await handleEventAtomic(event, ctx);
        const insertCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO validations")
        );
        expect(insertCall).toBeDefined();
        expect(insertCall![1]).toContain("PENDING");
      });

      it("ValidationResponded", async () => {
        const event = {
          type: "ValidationResponded" as const,
          data: {
            asset: TEST_ASSET,
            validatorAddress: TEST_VALIDATOR,
            nonce: 5n,
            response: 95,
            responseUri: "ipfs://QmValResp",
            responseHash: TEST_HASH,
            tag: "audit",
          },
        };
        await handleEventAtomic(event, ctx);
        const upsertCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("INSERT INTO validations") && c[0].includes("response")
        );
        expect(upsertCall).toBeDefined();
        expect(upsertCall![1]).toContain("RESPONDED");
      });

      it("Unknown event type in atomic handler", async () => {
        const event = { type: "FutureEvent", data: {} } as any;
        await handleEventAtomic(event, ctx);
        // Should not throw, just logs warning and commits
        const queries = mockClientInstance.query.mock.calls.map((c: any[]) => c[0]);
        expect(queries).toContain("COMMIT");
      });
    });

    describe("updateCursorAtomic", () => {
      it("should include monotonic guard in cursor SQL", async () => {
        const event = {
          type: "AtomEnabled" as const,
          data: { asset: TEST_ASSET, enabledBy: TEST_OWNER },
        };
        await handleEventAtomic(event, { ...ctx, source: "websocket" as const });
        const cursorCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("indexer_state") && c[0].includes("last_slot <= EXCLUDED.last_slot")
        );
        expect(cursorCall).toBeDefined();
        expect(cursorCall![1]).toContain("websocket");
      });
    });
  });

  // =========================================================================
  // ensureCollection / ensureCollectionTx + LRU cache
  // =========================================================================

  describe("ensureCollection + LRU cache", () => {
    it("should cache collection after successful insert (non-tx path)", async () => {
      // Use a unique collection that hasn't been seen in prior tests
      const CACHE_TEST_COLL = new PublicKey(new Uint8Array(32).fill(77));
      const event = {
        type: "AgentRegistered" as const,
        data: {
          asset: TEST_ASSET,
          collection: CACHE_TEST_COLL,
          owner: TEST_OWNER,
          atomEnabled: false,
          agentUri: "",
        },
      };
      await handleEvent(event, ctx);

      const collectionInserts1 = mockPoolInstance.query.mock.calls.filter((c: any[]) =>
        typeof c[0] === "string" && c[0].includes("INSERT INTO collections") && c[0].includes("ON CONFLICT (collection)")
      );
      expect(collectionInserts1.length).toBe(1);

      // Second call with same collection: should use cache, no new collection insert
      mockPoolInstance.query.mockClear();
      mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 0 });
      await handleEvent(event, ctx);

      const collectionInserts2 = mockPoolInstance.query.mock.calls.filter((c: any[]) =>
        typeof c[0] === "string" && c[0].includes("INSERT INTO collections") && c[0].includes("ON CONFLICT (collection)")
      );
      expect(collectionInserts2.length).toBe(0);
    });

    it("should not cache collection on DB error (non-tx path)", async () => {
      // Use a unique collection to avoid cache from previous tests
      const UNIQUE_COLLECTION = new PublicKey(new Uint8Array(32).fill(55));
      mockPoolInstance.query.mockRejectedValueOnce(new Error("collection insert fail"));
      mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 0 });

      const event = {
        type: "AgentRegistered" as const,
        data: {
          asset: TEST_ASSET,
          collection: UNIQUE_COLLECTION,
          owner: TEST_OWNER,
          atomEnabled: false,
          agentUri: "",
        },
      };
      await handleEvent(event, ctx);

      // Second attempt should retry the collection insert (not cached)
      mockPoolInstance.query.mockClear();
      mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 0 });
      await handleEvent(event, ctx);

      const collectionInserts = mockPoolInstance.query.mock.calls.filter((c: any[]) =>
        typeof c[0] === "string" && c[0].includes("INSERT INTO collections") && c[0].includes("ON CONFLICT (collection)")
      );
      expect(collectionInserts.length).toBe(1); // retried
    });

    it("ensureCollectionTx should throw on error", async () => {
      mockClientInstance.query
        .mockResolvedValueOnce(undefined) // BEGIN
        .mockRejectedValueOnce(new Error("tx collection fail")); // collection insert fails

      const UNIQUE_COLLECTION2 = new PublicKey(new Uint8Array(32).fill(66));
      const event = {
        type: "AgentRegistered" as const,
        data: {
          asset: TEST_ASSET,
          collection: UNIQUE_COLLECTION2,
          owner: TEST_OWNER,
          atomEnabled: false,
          agentUri: "",
        },
      };
      await expect(handleEventAtomic(event, ctx)).rejects.toThrow("tx collection fail");
    });

    it("should evict oldest entry when LRU cache reaches 1000 entries", async () => {
      // Fill cache to capacity by registering many agents with unique collections
      // We can trigger this by calling handleEvent with 1000+ unique collections
      // But that's slow. Instead, we test the internals indirectly:
      // The seenCollections is module-level. We need to fill it.
      // Use the atomic handler to add many collections.

      // Reset all collection mocks
      mockClientInstance.query.mockResolvedValue({ rows: [], rowCount: 0 });

      // Register 1001 agents with unique collections to trigger eviction
      for (let i = 100; i <= 1100; i++) {
        const collBytes = new Uint8Array(32).fill(0);
        collBytes[0] = i & 0xff;
        collBytes[1] = (i >> 8) & 0xff;
        const coll = new PublicKey(collBytes);
        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: coll,
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "",
          },
        };
        await handleEventAtomic(event, ctx);
        mockClientInstance.query.mockClear();
        mockClientInstance.query.mockResolvedValue({ rows: [], rowCount: 0 });
      }
      // If we got here without error, eviction worked
    });
  });

  // =========================================================================
  // hashesMatchHex
  // =========================================================================

  describe("hashesMatchHex (tested via FeedbackRevoked/ResponseAppended)", () => {
    it("both empty (null) should match", async () => {
      // Both stored and event hash are null -> match (no warning)
      mockPoolInstance.query
        .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: null }], rowCount: 1 })
        .mockResolvedValue({ rows: [], rowCount: 1 });

      const event = {
        type: "FeedbackRevoked" as const,
        data: {
          asset: TEST_ASSET,
          clientAddress: TEST_CLIENT,
          feedbackIndex: 0n,
          sealHash: null as any,
          slot: 123n,
          originalScore: 80,
          atomEnabled: false,
          hadImpact: false,
          newTrustTier: 0,
          newQualityScore: 0,
          newConfidence: 0,
          newRevokeDigest: TEST_HASH,
          newRevokeCount: 1n,
        },
      };
      await handleEvent(event, ctx);
    });

    it("both zero hashes should match", async () => {
      const zeroHash = "0".repeat(64);
      mockPoolInstance.query
        .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: zeroHash }], rowCount: 1 })
        .mockResolvedValue({ rows: [], rowCount: 1 });

      const zeroBytes = new Uint8Array(32).fill(0);
      const event = {
        type: "FeedbackRevoked" as const,
        data: {
          asset: TEST_ASSET,
          clientAddress: TEST_CLIENT,
          feedbackIndex: 0n,
          sealHash: zeroBytes,
          slot: 123n,
          originalScore: 80,
          atomEnabled: false,
          hadImpact: false,
          newTrustTier: 0,
          newQualityScore: 0,
          newConfidence: 0,
          newRevokeDigest: TEST_HASH,
          newRevokeCount: 1n,
        },
      };
      await handleEvent(event, ctx);
    });

    it("one empty one not should not match", async () => {
      mockPoolInstance.query
        .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: null }], rowCount: 1 })
        .mockResolvedValue({ rows: [], rowCount: 1 });

      const event = {
        type: "FeedbackRevoked" as const,
        data: {
          asset: TEST_ASSET,
          clientAddress: TEST_CLIENT,
          feedbackIndex: 0n,
          sealHash: TEST_HASH, // non-null
          slot: 123n,
          originalScore: 80,
          atomEnabled: false,
          hadImpact: false,
          newTrustTier: 0,
          newQualityScore: 0,
          newConfidence: 0,
          newRevokeDigest: TEST_HASH,
          newRevokeCount: 1n,
        },
      };
      await handleEvent(event, ctx);
      // This triggers the mismatch warning path
    });

    it("matching hashes should not warn", async () => {
      const matchingHash = Buffer.from(TEST_HASH).toString("hex");
      mockPoolInstance.query
        .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: matchingHash }], rowCount: 1 })
        .mockResolvedValue({ rows: [], rowCount: 1 });

      const event = {
        type: "FeedbackRevoked" as const,
        data: {
          asset: TEST_ASSET,
          clientAddress: TEST_CLIENT,
          feedbackIndex: 0n,
          sealHash: TEST_HASH,
          slot: 123n,
          originalScore: 80,
          atomEnabled: false,
          hadImpact: false,
          newTrustTier: 0,
          newQualityScore: 0,
          newConfidence: 0,
          newRevokeDigest: TEST_HASH,
          newRevokeCount: 1n,
        },
      };
      await handleEvent(event, ctx);
    });
  });

  // =========================================================================
  // logStatsIfNeeded
  // =========================================================================

  describe("logStatsIfNeeded (tested via handleEvent)", () => {
    it("should not log when within 60s window", async () => {
      // Default: lastLogTime is recent, so no logging
      const event = {
        type: "AgentOwnerSynced" as const,
        data: { asset: TEST_ASSET, oldOwner: TEST_OWNER, newOwner: TEST_NEW_OWNER },
      };
      await handleEvent(event, ctx);
      // No assertion needed - just verifying no error occurs
    });

    it("should log stats after 60s window", async () => {
      // Manipulate Date.now to simulate 61s gap
      const realDateNow = Date.now;
      let callIdx = 0;
      const baseTime = realDateNow();
      vi.spyOn(Date, "now").mockImplementation(() => {
        callIdx++;
        // Return a time that's > 60s from lastLogTime
        return baseTime + 120000;
      });

      const event = {
        type: "AgentOwnerSynced" as const,
        data: { asset: TEST_ASSET, oldOwner: TEST_OWNER, newOwner: TEST_NEW_OWNER },
      };
      await handleEvent(event, ctx);

      vi.spyOn(Date, "now").mockRestore();
    });
  });

  // =========================================================================
  // loadIndexerState()
  // =========================================================================

  describe("loadIndexerState()", () => {
    it("should return saved state with signature and slot", async () => {
      mockPoolInstance.query.mockResolvedValueOnce({
        rows: [{ last_signature: "sig123", last_slot: "99999" }],
        rowCount: 1,
      });
      const state = await loadIndexerState();
      expect(state.lastSignature).toBe("sig123");
      expect(state.lastSlot).toBe(99999n);
    });

    it("should return null slot when last_slot is null", async () => {
      mockPoolInstance.query.mockResolvedValueOnce({
        rows: [{ last_signature: "sig123", last_slot: null }],
        rowCount: 1,
      });
      const state = await loadIndexerState();
      expect(state.lastSignature).toBe("sig123");
      expect(state.lastSlot).toBeNull();
    });

    it("should return null state when signature is null (deployment fallback)", async () => {
      mockPoolInstance.query.mockResolvedValueOnce({
        rows: [{ last_signature: null, last_slot: null }],
        rowCount: 1,
      });
      const state = await loadIndexerState();
      expect(state.lastSignature).toBeNull();
      expect(state.lastSlot).toBeNull();
    });

    it("should return null state when no rows found", async () => {
      mockPoolInstance.query.mockResolvedValueOnce({ rows: [], rowCount: 0 });
      const state = await loadIndexerState();
      expect(state.lastSignature).toBeNull();
      expect(state.lastSlot).toBeNull();
    });

    it("should return null state on query error (fallback)", async () => {
      mockPoolInstance.query.mockRejectedValueOnce(new Error("db down"));
      const state = await loadIndexerState();
      expect(state.lastSignature).toBeNull();
      expect(state.lastSlot).toBeNull();
    });
  });

  // =========================================================================
  // saveIndexerState()
  // =========================================================================

  describe("saveIndexerState()", () => {
    it("should upsert state with monotonic guard", async () => {
      await saveIndexerState("sig456", 100000n);
      const upsertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
        typeof c[0] === "string" && c[0].includes("INSERT INTO indexer_state")
      );
      expect(upsertCall).toBeDefined();
      expect(upsertCall![1]).toContain("sig456");
      expect(upsertCall![1]).toContain("100000");
    });

    it("should catch query error", async () => {
      mockPoolInstance.query.mockRejectedValueOnce(new Error("save fail"));
      await saveIndexerState("sig", 1n);
      // Should not throw
    });
  });

  // =========================================================================
  // digestAndStoreUriMetadata (tested via handleEvent with metadataIndexMode on)
  // =========================================================================

  describe("digestAndStoreUriMetadata", () => {
    beforeEach(() => {
      mockDigestUri.mockClear();
      mockSerializeValue.mockClear();
      mockCompressForStorage.mockClear();
      mockCompressForStorage.mockResolvedValue(
        Buffer.concat([Buffer.from([0x00]), Buffer.from("test")])
      );
    });

    it("should skip when metadataIndexMode is off", async () => {
      // Default is off, so triggering AgentRegistered with URI should NOT digest
      const event = {
        type: "AgentRegistered" as const,
        data: {
          asset: TEST_ASSET,
          collection: TEST_COLLECTION,
          owner: TEST_OWNER,
          atomEnabled: false,
          agentUri: "ipfs://QmTest",
        },
      };
      await handleEvent(event, ctx);
      expect(mockDigestUri).not.toHaveBeenCalled();
    });

    it("should digest when metadataIndexMode is normal and URI present (non-tx)", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmTest" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:name": "TestAgent" },
          bytes: 100,
          hash: "abc",
        });
        mockSerializeValue.mockReturnValue({ value: "TestAgent", oversize: false, bytes: 9 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(83)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmTest",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        expect(mockDigestUri).toHaveBeenCalledWith("ipfs://QmTest");
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should handle agent not found (race condition check)", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [], rowCount: 0 }); // agent not found
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(81)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmStale",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        expect(mockDigestUri).not.toHaveBeenCalled();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should skip when URI changed (race condition)", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        // Use a smart mock that returns the right response based on query text
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmDifferent" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(80)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmOriginal",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        expect(mockDigestUri).not.toHaveBeenCalled();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should handle freshness check query error", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.reject(new Error("freshness check fail"));
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(82)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmFreshnessErr",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        expect(mockDigestUri).not.toHaveBeenCalled();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should store error status when digest fails", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmFail" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockResolvedValue({
          status: "error",
          error: "timeout",
          fields: null,
          bytes: 0,
          hash: null,
        });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(84)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmFail",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        expect(mockDigestUri).toHaveBeenCalledWith("ipfs://QmFail");
        const statusInsert = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" &&
          c[0].includes("INSERT INTO metadata") &&
          c[1]?.[2] === "_uri:_status"
        );
        expect(statusInsert).toBeDefined();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should handle oversize fields", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmOversize" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:description": "x".repeat(20000) },
          bytes: 20000,
          hash: "bighash",
        });
        mockSerializeValue.mockReturnValue({ value: "", oversize: true, bytes: 20000 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(85)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmOversize",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        const metaInsert = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" &&
          c[0].includes("INSERT INTO metadata") &&
          c[1]?.[2]?.endsWith("_meta")
        );
        expect(metaInsert).toBeDefined();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should sync nft_name from _uri:name", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmName" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:name": "MyAgent" },
          bytes: 50,
          hash: "h",
        });
        mockSerializeValue.mockReturnValue({ value: "MyAgent", oversize: false, bytes: 7 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(86)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmName",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        const nftNameUpdate = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("nft_name")
        );
        expect(nftNameUpdate).toBeDefined();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should not sync nft_name when _uri:name is not a string", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmNoName" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:description": "desc only" },
          bytes: 50,
          hash: "h",
        });
        mockSerializeValue.mockReturnValue({ value: "desc only", oversize: false, bytes: 9 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(87)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmNoName",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        const nftNameUpdate = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("nft_name")
        );
        expect(nftNameUpdate).toBeUndefined();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should handle nft_name sync failure gracefully", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        let callCount = 0;
        mockPoolInstance.query.mockImplementation((text: string) => {
          callCount++;
          if (typeof text === "string" && text.includes("nft_name")) {
            throw new Error("nft_name update fail");
          }
          return { rows: [{ agent_uri: "ipfs://QmSyncFail" }], rowCount: 1 };
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:name": "Agent" },
          bytes: 50,
          hash: "h",
        });
        mockSerializeValue.mockReturnValue({ value: "Agent", oversize: false, bytes: 5 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: TEST_COLLECTION,
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmSyncFail",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 50));
        // Should not throw
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should purge old URI metadata before storing new ones", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmPurge" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:name": "X" },
          bytes: 10,
          hash: "p",
        });
        mockSerializeValue.mockReturnValue({ value: "X", oversize: false, bytes: 1 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(88)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmPurge",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        const purgeCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("DELETE FROM metadata") && c[0].includes("_uri:")
        );
        expect(purgeCall).toBeDefined();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should handle purge failure gracefully and continue", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        let queryCount = 0;
        mockPoolInstance.query.mockImplementation((text: string) => {
          queryCount++;
          if (typeof text === "string" && text.includes("DELETE FROM metadata") && text.includes("_uri:")) {
            throw new Error("purge fail");
          }
          return { rows: [{ agent_uri: "ipfs://QmPurgeFail" }], rowCount: 1 };
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:name": "Y" },
          bytes: 10,
          hash: "q",
        });
        mockSerializeValue.mockReturnValue({ value: "Y", oversize: false, bytes: 1 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: TEST_COLLECTION,
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmPurgeFail",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 50));
        // Should continue despite purge failure
        expect(mockDigestUri).toHaveBeenCalled();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });
  });

  // =========================================================================
  // storeUriMetadata
  // =========================================================================

  describe("storeUriMetadata (tested via digestAndStoreUriMetadata)", () => {
    it("should store standard field raw (no compression)", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmStandard" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:name": "StandardAgent" },
          bytes: 50,
          hash: "s",
        });
        mockSerializeValue.mockReturnValue({ value: "StandardAgent", oversize: false, bytes: 13 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(89)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmStandard",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));

        // _uri:name is a STANDARD_URI_FIELD, should NOT call compressForStorage for the name field
        // Only _uri:_status (also standard) is stored, both use raw prefix
        // Verify URI-derived metadata was stored
        const uriInsert = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" && c[0].includes("uri_derived")
        );
        expect(uriInsert).toBeDefined();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should compress non-standard fields", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmNonStd" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:custom_field": "custom data" },
          bytes: 50,
          hash: "c",
        });
        mockSerializeValue.mockReturnValue({ value: "custom data", oversize: false, bytes: 11 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(90)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmNonStd",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        // compressForStorage should be called for non-standard field
        expect(mockCompressForStorage).toHaveBeenCalled();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should handle storeUriMetadata query failure gracefully", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        let queryIdx = 0;
        mockPoolInstance.query.mockImplementation((text: string) => {
          queryIdx++;
          if (typeof text === "string" && text.includes("INSERT INTO metadata") && text.includes("uri_derived")) {
            throw new Error("store fail");
          }
          return { rows: [{ agent_uri: "ipfs://QmStoreFail" }], rowCount: 1 };
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:name": "Z" },
          bytes: 10,
          hash: "f",
        });
        mockSerializeValue.mockReturnValue({ value: "Z", oversize: false, bytes: 1 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: TEST_COLLECTION,
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmStoreFail",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 50));
        // Should not throw
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should store truncatedKeys info in status metadata", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmTruncated" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:name": "T" },
          bytes: 100,
          hash: "t",
          truncatedKeys: true,
        });
        mockSerializeValue.mockReturnValue({ value: "T", oversize: false, bytes: 1 });

        const event = {
          type: "AgentRegistered" as const,
          data: {
            asset: TEST_ASSET,
            collection: new PublicKey(new Uint8Array(32).fill(91)),
            owner: TEST_OWNER,
            atomEnabled: false,
            agentUri: "ipfs://QmTruncated",
          },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));

        const statusInsert = mockPoolInstance.query.mock.calls.find((c: any[]) =>
          typeof c[0] === "string" &&
          c[0].includes("INSERT INTO metadata") &&
          c[0].includes("uri_derived") &&
          c[1]?.[2] === "_uri:_status"
        );
        expect(statusInsert).toBeDefined();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });
  });

  // =========================================================================
  // UriUpdated triggers digestAndStoreUriMetadata (non-tx path)
  // =========================================================================

  describe("UriUpdated metadata extraction (non-tx path)", () => {
    it("should trigger metadata extraction on URI update when mode is on", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmUpdated" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: { "_uri:name": "Updated" },
          bytes: 50,
          hash: "u",
        });
        mockSerializeValue.mockReturnValue({ value: "Updated", oversize: false, bytes: 7 });

        const event = {
          type: "UriUpdated" as const,
          data: { asset: TEST_ASSET, newUri: "ipfs://QmUpdated", updatedBy: TEST_OWNER },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        expect(mockDigestUri).toHaveBeenCalledWith("ipfs://QmUpdated");
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should not trigger metadata extraction on empty URI update", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        const event = {
          type: "UriUpdated" as const,
          data: { asset: TEST_ASSET, newUri: "", updatedBy: TEST_OWNER },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 50));
        expect(mockDigestUri).not.toHaveBeenCalled();
      } finally {
        (config as any).metadataIndexMode = "off";
      }
    });

    it("should catch and log error from digestAndStoreUriMetadata (.catch path)", async () => {
      (config as any).metadataIndexMode = "normal";
      try {
        // Make digestUri reject with an unhandled error.
        // The freshness check passes, purge passes, then digestUri throws.
        // This triggers the .catch() in handleUriUpdated line 899.
        mockPoolInstance.query.mockImplementation((text: string) => {
          if (typeof text === "string" && text.includes("SELECT agent_uri")) {
            return Promise.resolve({ rows: [{ agent_uri: "ipfs://QmErr" }], rowCount: 1 });
          }
          return Promise.resolve({ rows: [], rowCount: 1 });
        });
        mockDigestUri.mockRejectedValue(new Error("digestUri exploded"));

        const event = {
          type: "UriUpdated" as const,
          data: { asset: TEST_ASSET, newUri: "ipfs://QmErr", updatedBy: TEST_OWNER },
        };
        await handleEvent(event, ctx);
        await new Promise((r) => setTimeout(r, 100));
        // Error is caught in .catch(), should not throw
      } finally {
        mockDigestUri.mockResolvedValue({
          status: "ok",
          fields: {},
          bytes: 0,
          hash: "abc",
        });
        (config as any).metadataIndexMode = "off";
      }
    });
  });

  // =========================================================================
  // EventStats tracking
  // =========================================================================

  describe("eventStats increments", () => {
    it("should increment agentRegistered on AgentRegistered", async () => {
      const event = {
        type: "AgentRegistered" as const,
        data: {
          asset: TEST_ASSET,
          collection: TEST_COLLECTION,
          owner: TEST_OWNER,
          atomEnabled: false,
          agentUri: "",
        },
      };
      await handleEvent(event, ctx);
      // Stats are incremented internally - no direct assertion possible
      // but no error means the path was reached
    });

    it("should increment metadataSet on MetadataSet", async () => {
      const event = {
        type: "MetadataSet" as const,
        data: { asset: TEST_ASSET, key: "k", value: new Uint8Array([1]), immutable: false },
      };
      await handleEvent(event, ctx);
    });

    it("should increment feedbackReceived on NewFeedback", async () => {
      mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 1 });
      const event = {
        type: "NewFeedback" as const,
        data: {
          asset: TEST_ASSET,
          clientAddress: TEST_CLIENT,
          feedbackIndex: 0n,
          slot: 0n,
          value: 100n,
          valueDecimals: 0,
          score: 50,
          feedbackFileHash: null,
          sealHash: TEST_HASH,
          atomEnabled: false,
          newTrustTier: 0,
          newQualityScore: 0,
          newConfidence: 0,
          newRiskScore: 0,
          newDiversityRatio: 0,
          isUniqueClient: false,
          newFeedbackDigest: TEST_HASH,
          newFeedbackCount: 1n,
          tag1: "",
          tag2: "",
          endpoint: "",
          feedbackUri: "",
        },
      };
      await handleEvent(event, ctx);
    });

    it("should increment validationRequested on ValidationRequested", async () => {
      const event = {
        type: "ValidationRequested" as const,
        data: {
          asset: TEST_ASSET,
          validatorAddress: TEST_VALIDATOR,
          nonce: 1n,
          requestUri: "",
          requestHash: TEST_HASH,
          requester: TEST_OWNER,
        },
      };
      await handleEvent(event, ctx);
    });

    it("should increment validationResponded on ValidationResponded", async () => {
      const event = {
        type: "ValidationResponded" as const,
        data: {
          asset: TEST_ASSET,
          validatorAddress: TEST_VALIDATOR,
          nonce: 1n,
          response: 80,
          responseUri: "",
          responseHash: TEST_HASH,
          tag: "",
        },
      };
      await handleEvent(event, ctx);
    });

    it("should increment errors on handleEvent error", async () => {
      const badEvent = Object.create(null);
      Object.defineProperty(badEvent, "type", {
        get() { throw new Error("boom"); }
      });
      try {
        await handleEvent(badEvent, ctx);
      } catch {
        // Expected
      }
    });

    it("should increment errors on handleEventAtomic error", async () => {
      mockClientInstance.query
        .mockResolvedValueOnce(undefined)
        .mockRejectedValueOnce(new Error("atomic fail"));

      const event = {
        type: "AtomEnabled" as const,
        data: { asset: TEST_ASSET, enabledBy: TEST_OWNER },
      };
      try {
        await handleEventAtomic(event, ctx);
      } catch {
        // Expected
      }
    });
  });

  // =========================================================================
  // Edge cases and special values
  // =========================================================================

  describe("Edge cases", () => {
    it("should handle null txIndex (uses null default)", async () => {
      const ctxNoTxIndex = { signature: TEST_SIGNATURE, slot: TEST_SLOT, blockTime: TEST_BLOCK_TIME };
      const event = {
        type: "AgentRegistered" as const,
        data: {
          asset: TEST_ASSET,
          collection: TEST_COLLECTION,
          owner: TEST_OWNER,
          atomEnabled: false,
          agentUri: "",
        },
      };
      await handleEvent(event, ctxNoTxIndex);
      const insertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
        typeof c[0] === "string" && c[0].includes("INSERT INTO agents")
      );
      expect(insertCall).toBeDefined();
      // txIndex should be null
      expect(insertCall![1][12]).toBeNull();
    });

    it("should handle ValidationRequested with null requestUri and requestHash", async () => {
      const event = {
        type: "ValidationRequested" as const,
        data: {
          asset: TEST_ASSET,
          validatorAddress: TEST_VALIDATOR,
          nonce: 10n,
          requestUri: "",
          requestHash: null as any,
          requester: TEST_OWNER,
        },
      };
      await handleEvent(event, ctx);
      const insertCall = mockPoolInstance.query.mock.calls.find((c: any[]) =>
        typeof c[0] === "string" && c[0].includes("INSERT INTO validations")
      );
      expect(insertCall).toBeDefined();
    });

    it("should handle ValidationResponded with null responseHash and tag", async () => {
      const event = {
        type: "ValidationResponded" as const,
        data: {
          asset: TEST_ASSET,
          validatorAddress: TEST_VALIDATOR,
          nonce: 10n,
          response: 75,
          responseUri: "",
          responseHash: null as any,
          tag: "",
        },
      };
      await handleEvent(event, ctx);
    });

    it("should handle NewFeedback with null optional fields", async () => {
      mockPoolInstance.query.mockResolvedValue({ rows: [], rowCount: 1 });
      const event = {
        type: "NewFeedback" as const,
        data: {
          asset: TEST_ASSET,
          clientAddress: TEST_CLIENT,
          feedbackIndex: 0n,
          slot: 0n,
          value: 100n,
          valueDecimals: 0,
          score: null,
          feedbackFileHash: null,
          sealHash: null as any,
          atomEnabled: false,
          newTrustTier: 0,
          newQualityScore: 0,
          newConfidence: 0,
          newRiskScore: 0,
          newDiversityRatio: 0,
          isUniqueClient: false,
          newFeedbackDigest: null as any,
          newFeedbackCount: 1n,
          tag1: "",
          tag2: "",
          endpoint: "",
          feedbackUri: "",
        },
      };
      await handleEvent(event, ctx);
    });

    it("should handle ResponseAppended with null responseHash and responseUri", async () => {
      mockPoolInstance.query
        .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: null }], rowCount: 1 })
        .mockResolvedValue({ rows: [], rowCount: 1 });

      const event = {
        type: "ResponseAppended" as const,
        data: {
          asset: TEST_ASSET,
          client: TEST_CLIENT,
          feedbackIndex: 0n,
          slot: 0n,
          responder: TEST_RESPONDER,
          responseUri: "",
          responseHash: null as any,
          sealHash: null as any,
          newResponseDigest: null as any,
          newResponseCount: 1n,
        },
      };
      await handleEvent(event, ctx);
    });

    it("should handle FeedbackRevoked with null sealHash", async () => {
      mockPoolInstance.query
        .mockResolvedValueOnce({ rows: [{ id: "x", feedback_hash: null }], rowCount: 1 })
        .mockResolvedValue({ rows: [], rowCount: 1 });

      const event = {
        type: "FeedbackRevoked" as const,
        data: {
          asset: TEST_ASSET,
          clientAddress: TEST_CLIENT,
          feedbackIndex: 0n,
          sealHash: null as any,
          slot: 0n,
          originalScore: 50,
          atomEnabled: false,
          hadImpact: false,
          newTrustTier: 0,
          newQualityScore: 0,
          newConfidence: 0,
          newRevokeDigest: null as any,
          newRevokeCount: 0n,
        },
      };
      await handleEvent(event, ctx);
    });
  });

  // =========================================================================
  // Atomic handler source field
  // =========================================================================

  describe("handleEventAtomic source field", () => {
    it("should pass 'poller' source to cursor when source is provided", async () => {
      const event = {
        type: "AtomEnabled" as const,
        data: { asset: TEST_ASSET, enabledBy: TEST_OWNER },
      };
      await handleEventAtomic(event, { ...ctx, source: "poller" as const });
      const cursorCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
        typeof c[0] === "string" && c[0].includes("indexer_state")
      );
      expect(cursorCall![1][2]).toBe("poller");
    });

    it("should pass 'websocket' source to cursor when source is websocket", async () => {
      const event = {
        type: "AtomEnabled" as const,
        data: { asset: TEST_ASSET, enabledBy: TEST_OWNER },
      };
      await handleEventAtomic(event, { ...ctx, source: "websocket" as const });
      const cursorCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
        typeof c[0] === "string" && c[0].includes("indexer_state")
      );
      expect(cursorCall![1][2]).toBe("websocket");
    });

    it("should default source to 'poller' when not specified", async () => {
      const event = {
        type: "AtomEnabled" as const,
        data: { asset: TEST_ASSET, enabledBy: TEST_OWNER },
      };
      await handleEventAtomic(event, { signature: ctx.signature, slot: ctx.slot, blockTime: ctx.blockTime, txIndex: ctx.txIndex });
      const cursorCall = mockClientInstance.query.mock.calls.find((c: any[]) =>
        typeof c[0] === "string" && c[0].includes("indexer_state")
      );
      expect(cursorCall![1][2]).toBe("poller");
    });
  });
});
